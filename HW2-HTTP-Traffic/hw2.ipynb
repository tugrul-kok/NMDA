{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_v/2_7ylzwd1r140fnllwbxf9hr0000gn/T/ipykernel_22738/2799138059.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([packets_df, pd.DataFrame([packet_dict])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code for https://www.washingtonpost.com: 200\n",
      "Status code for https://www.ndtv.com: 200\n",
      "Status code for https://www.ndtv.com: 200\n",
      "Status code for https://www.ndtv.com: 200\n",
      "Status code for https://www.ndtv.com: 200\n",
      "Status code for https://www.ndtv.com: 200\n",
      "Status code for https://www.ndtv.com: 200\n",
      "Status code for https://www.ndtv.com: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_v/2_7ylzwd1r140fnllwbxf9hr0000gn/T/ipykernel_22738/2799138059.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([packets_df, pd.DataFrame([packet_dict])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code for https://www.ndtv.com: 200\n",
      "Status code for https://www.ndtv.com: 200\n",
      "Status code for https://www.ndtv.com: 200\n",
      "Status code for https://www.washingtonpost.com: 200\n",
      "Status code for https://www.washingtonpost.com: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_v/2_7ylzwd1r140fnllwbxf9hr0000gn/T/ipykernel_22738/2799138059.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([packets_df, pd.DataFrame([packet_dict])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code for https://www.cnbc.com: 200\n",
      "Status code for https://www.cnbc.com: 200\n",
      "Status code for https://www.cnbc.com: 200\n",
      "Status code for https://www.cnbc.com: 200\n",
      "Status code for https://www.cnbc.com: 200\n",
      "Status code for https://www.cnbc.com: 200\n",
      "Status code for https://www.cnbc.com: 200\n",
      "Status code for https://www.cnbc.com: 200\n",
      "Status code for https://www.cnbc.com: 200\n",
      "Status code for https://www.cnbc.com: 200\n",
      "Status code for https://www.washingtonpost.com: 200\n",
      "Status code for https://www.timesofindia.com: 200\n",
      "Status code for https://www.timesofindia.com: 200\n",
      "Status code for https://www.timesofindia.com: 200\n",
      "Status code for https://www.timesofindia.com: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_v/2_7ylzwd1r140fnllwbxf9hr0000gn/T/ipykernel_22738/2799138059.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([packets_df, pd.DataFrame([packet_dict])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code for https://www.timesofindia.com: 200\n",
      "Status code for https://www.timesofindia.com: 200\n",
      "Status code for https://www.timesofindia.com: 200\n",
      "Status code for https://www.timesofindia.com: 200\n",
      "Status code for https://www.timesofindia.com: 200\n",
      "Status code for https://www.timesofindia.com: 200\n",
      "Status code for https://www.washingtonpost.com: 200\n",
      "Status code for https://www.express.co.uk: 200\n",
      "Status code for https://www.express.co.uk: 200\n",
      "Status code for https://www.express.co.uk: 200\n",
      "Status code for https://www.express.co.uk: 200\n",
      "Status code for https://www.express.co.uk: 200\n",
      "Status code for https://www.washingtonpost.com: 200\n",
      "Status code for https://www.express.co.uk: 200\n",
      "Status code for https://www.express.co.uk: 200\n",
      "Status code for https://www.express.co.uk: 200\n",
      "Status code for https://www.express.co.uk: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_v/2_7ylzwd1r140fnllwbxf9hr0000gn/T/ipykernel_22738/2799138059.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([packets_df, pd.DataFrame([packet_dict])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code for https://www.express.co.uk: 200\n",
      "Status code for https://www.washingtonpost.com: 200\n",
      "Status code for https://www.cnn.com: 200\n",
      "Status code for https://www.cnn.com: 200\n",
      "Status code for https://www.cnn.com: 200\n",
      "Status code for https://www.cnn.com: 200\n",
      "Status code for https://www.cnn.com: 200\n",
      "Status code for https://www.cnn.com: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_v/2_7ylzwd1r140fnllwbxf9hr0000gn/T/ipykernel_22738/2799138059.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([packets_df, pd.DataFrame([packet_dict])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code for https://www.cnn.com: 200\n",
      "Status code for https://www.cnn.com: 200\n",
      "Status code for https://www.cnn.com: 200\n",
      "Status code for https://www.cnn.com: 200\n",
      "Status code for https://www.washingtonpost.com: 200\n",
      "Status code for https://www.news18.com: 200\n",
      "Status code for https://www.news18.com: 200\n",
      "Status code for https://www.news18.com: 200\n",
      "Status code for https://www.news18.com: 200\n",
      "Status code for https://www.news18.com: 200\n",
      "Status code for https://www.news18.com: 200\n",
      "Status code for https://www.news18.com: 200\n",
      "Status code for https://www.news18.com: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_v/2_7ylzwd1r140fnllwbxf9hr0000gn/T/ipykernel_22738/2799138059.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([packets_df, pd.DataFrame([packet_dict])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code for https://www.news18.com: 200\n",
      "Status code for https://www.news18.com: 200\n",
      "Status code for https://www.washingtonpost.com: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_v/2_7ylzwd1r140fnllwbxf9hr0000gn/T/ipykernel_22738/2799138059.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([packets_df, pd.DataFrame([packet_dict])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code for https://www.washingtonpost.com: 200\n",
      "Status code for https://www.nypost.com: 200\n",
      "Status code for https://www.nypost.com: 200\n",
      "Status code for https://www.nypost.com: 200\n",
      "Status code for https://www.nypost.com: 200\n",
      "Status code for https://www.nypost.com: 200\n",
      "Status code for https://www.nypost.com: 200\n",
      "Status code for https://www.nypost.com: 200\n",
      "Status code for https://www.nypost.com: 200\n",
      "Status code for https://www.nypost.com: 200\n",
      "Status code for https://www.nypost.com: 200\n"
     ]
    }
   ],
   "source": [
    "import pyshark\n",
    "import pandas as pd\n",
    "import threading\n",
    "import requests\n",
    "\n",
    "def packet_to_dict(pkt):\n",
    "    packet_dict = {\n",
    "        'time': pkt.sniff_time.timestamp(),\n",
    "        'frame_number': pkt.frame_info.number,\n",
    "        'protocol': pkt.highest_layer,\n",
    "        'source': pkt.ip.src if hasattr(pkt, 'ip') else None,\n",
    "        'destination': pkt.ip.dst if hasattr(pkt, 'ip') else None,\n",
    "        'length': int(pkt.length),\n",
    "        'ttl': int(pkt.ip.ttl) if hasattr(pkt, 'ip') else None,\n",
    "        'source_port': int(pkt[pkt.transport_layer].srcport) if pkt.transport_layer else None,\n",
    "        'destination_port': int(pkt[pkt.transport_layer].dstport) if pkt.transport_layer else None,\n",
    "        'tcp_flags': int(pkt.tcp.flags, 16) if hasattr(pkt, 'tcp') else None,\n",
    "        'dns_query': pkt.dns.qry_name if hasattr(pkt, 'dns') and hasattr(pkt.dns, 'qry_name') else None,\n",
    "        'dns_response': [resp.addr for resp in pkt.dns.resp_addr.all_fields] if hasattr(pkt, 'dns') and hasattr(pkt.dns, 'resp_addr') else None,\n",
    "        'http_request_method': pkt.http.request_method if hasattr(pkt, 'http') and hasattr(pkt.http, 'request_method') else None,\n",
    "        'http_host': pkt.http.host if hasattr(pkt, 'http') and hasattr(pkt.http, 'host') else None,\n",
    "        'http_user_agent': pkt.http.user_agent if hasattr(pkt, 'http') and hasattr(pkt.http, 'user_agent') else None,\n",
    "        'ssl_version': pkt.ssl.version if hasattr(pkt, 'ssl') and hasattr(pkt.ssl, 'version') else None,\n",
    "        'tls_handshake_type': pkt.tls.handshake_type if hasattr(pkt, 'tls') and hasattr(pkt.tls, 'handshake_type') else None,\n",
    "        # Add more fields as needed\n",
    "    }\n",
    "    return packet_dict\n",
    "\n",
    "def packet_callback(pkt, packets_df):\n",
    "    if isinstance(packets_df, pd.DataFrame):\n",
    "        packet_dict = packet_to_dict(pkt)\n",
    "        return pd.concat([packets_df, pd.DataFrame([packet_dict])], ignore_index=True)\n",
    "    else:\n",
    "        print(\"Error: packets_df is not a DataFrame.\")\n",
    "        return None\n",
    "\n",
    "import requests\n",
    "\n",
    "def capture_packets(website):\n",
    "    packets_df = pd.DataFrame(columns=['time', 'frame_number', 'protocol', 'source', 'destination', \n",
    "                                        'length', 'ttl', 'source_port', 'destination_port', 'tcp_flags'])\n",
    "    # Start capturing packets\n",
    "    capture = pyshark.LiveCapture(interface='en0', display_filter='tcp or dns or http or ssl or tls')\n",
    "    capture.sniff(timeout=10)\n",
    "\n",
    "    # Start a new thread for making the request\n",
    "    def make_request():\n",
    "        for _ in range(10):\n",
    "            try:\n",
    "                response = requests.get(website)\n",
    "                print(f\"Status code for {website}: {response.status_code}\")\n",
    "            except requests.exceptions.ConnectionError:\n",
    "                print(f\"Error: Failed to establish a new connection to {website}\")\n",
    "\n",
    "    request_thread = threading.Thread(target=make_request)\n",
    "    request_thread.start()\n",
    "\n",
    "    # Iterate over captured packets and store them in DataFrame\n",
    "    for packet in capture.sniff_continuously(packet_count=10):\n",
    "        packets_df = packet_callback(packet, packets_df)\n",
    "        if packets_df is None:\n",
    "            break  # Stop capturing if DataFrame becomes invalid\n",
    "\n",
    "    # Append DataFrame to CSV\n",
    "    with open(f'captures/{website.replace(\"https://\", \"\").replace(\"/\", \"_\")}.csv', 'a') as f:\n",
    "        packets_df.to_csv(f, header=f.tell()==0, index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # List of websites to visit\n",
    "    websites = [\"https://www.washingtonpost.com\", \"https://www.ndtv.com\", \"https://www.cnbc.com\", \n",
    "                \"https://www.timesofindia.com\", \"https://www.express.co.uk\", \"https://www.cnn.com\", \n",
    "                \"https://www.news18.com\", \"https://www.nypost.com\", \"https://www.abc.net.au\"]\n",
    "\n",
    "    # Create a separate thread for packet capture for each website\n",
    "    for website in websites:\n",
    "        capture_thread = threading.Thread(target=capture_packets, args=(website,))\n",
    "        capture_thread.start()\n",
    "        capture_thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            time  frame_number protocol         source    destination  length  \\\n",
      "0   1.711166e+09             1      TCP   20.44.10.122   192.168.1.53      66   \n",
      "1   1.711166e+09             2      TLS   192.168.1.53  20.189.173.18      90   \n",
      "2   1.711166e+09             3      TLS   192.168.1.53   17.57.146.22     106   \n",
      "3   1.711166e+09             4      TLS  20.189.173.18   192.168.1.53     531   \n",
      "4   1.711166e+09             5      TCP   192.168.1.53  20.189.173.18      78   \n",
      "5   1.711166e+09             6      TLS  20.189.173.18   192.168.1.53     531   \n",
      "6   1.711166e+09             7      TLS    3.68.61.181   192.168.1.53    1145   \n",
      "7   1.711166e+09             8      TCP   192.168.1.53  20.189.173.18      90   \n",
      "8   1.711166e+09             9      TCP   192.168.1.53  20.189.173.18      78   \n",
      "9   1.711166e+09            10      TCP   192.168.1.53    3.68.61.181      66   \n",
      "10  1.711166e+09             1      TCP            NaN            NaN      86   \n",
      "11  1.711166e+09             2      TCP            NaN            NaN      86   \n",
      "12  1.711166e+09             3      TCP            NaN            NaN      86   \n",
      "13  1.711166e+09             6      DNS            NaN            NaN      93   \n",
      "14  1.711166e+09             7      DNS            NaN            NaN      93   \n",
      "15  1.711166e+09             8      DNS            NaN            NaN     202   \n",
      "16  1.711166e+09             9      DNS            NaN            NaN     187   \n",
      "17  1.711166e+09            10      TCP   192.168.1.53    3.68.175.98      78   \n",
      "18  1.711166e+09            11      TCP    3.68.175.98   192.168.1.53      74   \n",
      "19  1.711166e+09            12      TCP   192.168.1.53    3.68.175.98      66   \n",
      "20  1.711166e+09             1      TLS   192.168.1.53    3.68.61.181     120   \n",
      "21  1.711166e+09             2      TCP    3.68.61.181   192.168.1.53      66   \n",
      "22  1.711166e+09             3      TLS    3.68.61.181   192.168.1.53     122   \n",
      "23  1.711166e+09             4      TCP   192.168.1.53    3.68.61.181      66   \n",
      "24  1.711166e+09             9      TLS   23.50.153.34   192.168.1.53    1514   \n",
      "25  1.711166e+09            10      TCP   23.50.153.34   192.168.1.53    1514   \n",
      "26  1.711166e+09            11      TCP   23.50.153.34   192.168.1.53    1514   \n",
      "27  1.711166e+09            12      TCP   23.50.153.34   192.168.1.53    1514   \n",
      "28  1.711166e+09            13      TCP   23.50.153.34   192.168.1.53    1514   \n",
      "29  1.711166e+09            14      TCP   23.50.153.34   192.168.1.53    1514   \n",
      "\n",
      "      ttl  source_port  destination_port  tcp_flags      dns_query  \\\n",
      "0   101.0          443             52026       16.0            NaN   \n",
      "1    64.0        52160               443       25.0            NaN   \n",
      "2    64.0        49980              5223       24.0            NaN   \n",
      "3    98.0          443             52160       25.0            NaN   \n",
      "4    64.0        52160               443       17.0            NaN   \n",
      "5    98.0          443             52160       25.0            NaN   \n",
      "6    51.0          443             51764       24.0            NaN   \n",
      "7    64.0        52160               443       25.0            NaN   \n",
      "8    64.0        52160               443       17.0            NaN   \n",
      "9    64.0        51764               443       16.0            NaN   \n",
      "10    NaN        52257               443       17.0            NaN   \n",
      "11    NaN          443             52257       17.0            NaN   \n",
      "12    NaN        52257               443       16.0            NaN   \n",
      "13    NaN        61439                53        NaN  app.slack.com   \n",
      "14    NaN        54079                53        NaN  app.slack.com   \n",
      "15    NaN           53             61439        NaN  app.slack.com   \n",
      "16    NaN           53             54079        NaN  app.slack.com   \n",
      "17   64.0        52262               443        2.0            NaN   \n",
      "18   52.0          443             52262       18.0            NaN   \n",
      "19   64.0        52262               443       16.0            NaN   \n",
      "20   64.0        51764               443       24.0            NaN   \n",
      "21   51.0          443             51764       16.0            NaN   \n",
      "22   51.0          443             51764       24.0            NaN   \n",
      "23   64.0        51764               443       16.0            NaN   \n",
      "24   52.0          443             52345       16.0            NaN   \n",
      "25   52.0          443             52345       16.0            NaN   \n",
      "26   52.0          443             52345       24.0            NaN   \n",
      "27   52.0          443             52345       16.0            NaN   \n",
      "28   52.0          443             52345       16.0            NaN   \n",
      "29   52.0          443             52345       24.0            NaN   \n",
      "\n",
      "    dns_response  http_request_method  http_host  http_user_agent  \\\n",
      "0            NaN                  NaN        NaN              NaN   \n",
      "1            NaN                  NaN        NaN              NaN   \n",
      "2            NaN                  NaN        NaN              NaN   \n",
      "3            NaN                  NaN        NaN              NaN   \n",
      "4            NaN                  NaN        NaN              NaN   \n",
      "5            NaN                  NaN        NaN              NaN   \n",
      "6            NaN                  NaN        NaN              NaN   \n",
      "7            NaN                  NaN        NaN              NaN   \n",
      "8            NaN                  NaN        NaN              NaN   \n",
      "9            NaN                  NaN        NaN              NaN   \n",
      "10           NaN                  NaN        NaN              NaN   \n",
      "11           NaN                  NaN        NaN              NaN   \n",
      "12           NaN                  NaN        NaN              NaN   \n",
      "13           NaN                  NaN        NaN              NaN   \n",
      "14           NaN                  NaN        NaN              NaN   \n",
      "15           NaN                  NaN        NaN              NaN   \n",
      "16           NaN                  NaN        NaN              NaN   \n",
      "17           NaN                  NaN        NaN              NaN   \n",
      "18           NaN                  NaN        NaN              NaN   \n",
      "19           NaN                  NaN        NaN              NaN   \n",
      "20           NaN                  NaN        NaN              NaN   \n",
      "21           NaN                  NaN        NaN              NaN   \n",
      "22           NaN                  NaN        NaN              NaN   \n",
      "23           NaN                  NaN        NaN              NaN   \n",
      "24           NaN                  NaN        NaN              NaN   \n",
      "25           NaN                  NaN        NaN              NaN   \n",
      "26           NaN                  NaN        NaN              NaN   \n",
      "27           NaN                  NaN        NaN              NaN   \n",
      "28           NaN                  NaN        NaN              NaN   \n",
      "29           NaN                  NaN        NaN              NaN   \n",
      "\n",
      "    ssl_version  tls_handshake_type  \n",
      "0           NaN                 NaN  \n",
      "1           NaN                 NaN  \n",
      "2           NaN                 NaN  \n",
      "3           NaN                 NaN  \n",
      "4           NaN                 NaN  \n",
      "5           NaN                 NaN  \n",
      "6           NaN                 NaN  \n",
      "7           NaN                 NaN  \n",
      "8           NaN                 NaN  \n",
      "9           NaN                 NaN  \n",
      "10          NaN                 NaN  \n",
      "11          NaN                 NaN  \n",
      "12          NaN                 NaN  \n",
      "13          NaN                 NaN  \n",
      "14          NaN                 NaN  \n",
      "15          NaN                 NaN  \n",
      "16          NaN                 NaN  \n",
      "17          NaN                 NaN  \n",
      "18          NaN                 NaN  \n",
      "19          NaN                 NaN  \n",
      "20          NaN                 NaN  \n",
      "21          NaN                 NaN  \n",
      "22          NaN                 NaN  \n",
      "23          NaN                 NaN  \n",
      "24          NaN                 NaN  \n",
      "25          NaN                 NaN  \n",
      "26          NaN                 NaN  \n",
      "27          NaN                 NaN  \n",
      "28          NaN                 NaN  \n",
      "29          NaN                 NaN  \n",
      "(30, 17)\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file from captures folder and make a single DataFrame\n",
    "df = pd.concat([pd.read_csv(f'captures/{website.replace(\"https://\", \"\").replace(\"/\", \"_\")}.csv') for website in websites], ignore_index=True)\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
